

# Strong


## DIVE Zach
The realm of computer-aided design (CAD) software has predominantly catered to professional demands, often at the expense of broader accessibility and user enjoyment. The significant learning curve, coupled with often unintuitive interfaces, poses a fundamental obstacle to innovation. The recent rise of autotelic tools, as illustrated by the term 'casual creators' (Compton & Mateus, 2015), redirects our focus towards a blend of creativity and pleasure, contrasting the traditional emphasis on mere productivity. While some innovations have ventured into combining generative interfaces with existing CAD software, a holistic approach catering to everyday creators with little prior knowledge still remains elusive.
Applying methodologies that employ generative machine learning, especially in 3D shape generation, prompt-based renderings, and natural language processing (NLP), offers a promising avenue to reframe the CAD environment. This exploration might not only restructure the foundational principles of CAD but also establish it as an efficient design collaborator (Steinfeld, 2023). 
The system proposed here - Adam - builds upon an existing open-source, script-based CAD framework to develop a natural language interface that in turn lowers its barrier to entry. By reimagining existing tools, the  goal is to design and prototype a CAD interface that appeals more broadly, especially to those unfamiliar with traditional CAD systems.
This research predominantly concentrates on the conceptualization and preliminary prototyping tailored for the casual creator demographic, deliberately circumventing an exhaustive analysis of industrial-scale software deployment.
By simplifying CAD methodologies, this research envisions a shift toward a computational design paradigm that is not only cost-effective but also intuitively accessible, promoting a democratized approach to design. 
While the current research is focused on conceptualization and preliminary prototyping for everyday creators, future endeavors could delve into extensive usability studies, refinement of the integrated AI for broader application domains, and potential to explore avenues of industrial-scale software deployment within the broader CAD ecosystem in more production-ready use cases.



## CHEN Nuoran

Much information nowadays is conveyed through graphics. However, for blind individuals, acquiring new concepts or abstract ideas from graphics is more challenging compared to their sighted counterparts. Unlike sighted individuals who effortlessly establish connections between visual signifiers and signified concepts, visual-impaired and blind (VIB) people rely on alternative senses such as touch or hearing to develop this cognitive relationship. As an essential part of blind special education, the teaching of graphics plays a pivotal role in enabling VIB students to form abstract recognitions, providing them with frameworks and techniques to comprehend our world at a more advanced level. The advent of emerging technologies has facilitated the creation of various tools for blind graphic education, including raised-line printing diagrams, tactile tablets, dot view tactile graphics display, camera-based hand movement tracker etc[1]. While those methods leverage tactile or audio-tactile approaches to assist blind students to some extent, they often prove either insufficiently efficient or financially prohibitive. Consequently, special education still heavily relies on one-on-one assistance from educators. This dependence is also influenced by the learning characteristics of VIB learners. Unlike sighted learners who learn new information in a “whole to part” way, tactile learners learn from “part to whole”. They need clearly structured guidance to go through each component in a graphic first and put all pieces of information in sequence to come up with a whole picture[2]. Thus, there is a crucial need to develop more guiding, cost-effective, and engaging graphic learning tools tailored to the needs of VBI learners. To anchor our design, we chose a specific graphic learning scenario within special education. Employing an ethnographic research method, we observed a blind Arduino class led by Joshua Miele. The class focused on imparting basic knowledge of electronic circuits circulation to a group of four blind students. After analyzing qualitative data from the observation, we identified two main pain points in the teaching-learning situation and proposed three solutions to improve tactile learning’s guidance, efficiency, and engagement in the blind Arduino class. Through two rounds of evaluative research with 5 blindfolded sighted individuals and 5 blind individuals, our camera-based audio-tactile vibrating system showed the effectiveness at enhancing both learning and teaching efficiency in the blind Arduino class. We believe this solution can be extended to other graphic learning scenarios for visually impaired individuals, including independent, remote, or collaborative learning. Acknowledging constraints in time and resources, our research and design isn’t perfect. It has inherent human error in the "Wizard of Oz" approach and the design lacks two-hand guidance. We also did not conduct comparative experiments with other audio-tactile solutions. Moving forward, refining and testing our design with larger user groups is essential, along with efforts to enhance the accuracy of hand guidance with reduced cognitive load.

## GARCIA Tomas

The US Geological Survey has identified the Hayward Fault, passing immediately underneath Berkeley’s campus, a ‘tectonic time bomb’, declaring it one of the most dangerous in the country because of its proximity to urban centers. When these impending earthquakes arrive, the ubiquitous connectivity provided by high-speed voice and data networks enabling our individual and collective endeavors will go offline and remain unavailable for hours, days, or weeks. Despite rigorous attempts to communicate this potential reality by regional, state, and federal governmental institutions, overwhelming portions of society remain unresponsive and unprepared, ensuring an exacerbation of the emotional shock and suffering that will arrive with the physical shaking. Using existing community institutions as a foundation, the creation of an alternative communication network leveraging emerging technologies like Long Range (LoRa) radio networks, provides an opportunity to create an affordable, resilient, and scalable communication network that can be used for basic status updates for our most vulnerable populations in the aftermath of a high-magnitude earthquake. By introducing and maintaining these tools through primary school curricula and facilities, these municipal institutions have the power to provide a resilient and accessible lifeline to a wide socioeconomic spectrum, created for and powered by community. This research will not seek to extend existing functionality of the proposed technologies but will focus on integration and presentation of these technologies in a singular presentation for maximum utility in the context of this specified scenario. By addressing blind spots in contemporary civil infrastructure, this project intends to illustrate how thoughtful deployments of simple technology can mitigate human suffering. While this research will focus on the Berkeley Unified School District as a pilot application, continued research into this domain might consider how these technologies can be applied to school districts of varying scales and socioeconomic circumstances. 


## BRECHBILL John

After billions of years of evolution, nature, as it exists on earth, is self-sufficient. Systems such as weather patterns and food chains operate on large scales over vast periods of time, without the need for additional input. However, confined to the sterile home of a human being, this natural world is no longer self-sufficient. Early on in human development, the advancement of technologies such as agriculture and architecture intentionally excluded this natural world from the home. As we introduced the natural world back into our homes in the form of house plants, we stripped these creatures of their previous autonomy and confined them to stagnant pots, in return gaining just a visually appealing object. It is my view that this is a shallow relationship. I propose that the future of human-nature interaction in the home relies on two important factors. One, the plant must gain physical autonomy to seek out what it needs most, liberating the plant from its tiny pot, and the human being must in turn benefit from this plant being in their home. There have been numerous projects in the past that have attempted to design for one of these proposals, yet never both. With recent technological advances in the fields of biology, sensing technologies, and computing, it is now possible to deepen this relationship between humans and plants. I propose the creation of a plant system called Microcosm that uses these advances to break the plant free from their dependency on the human in the form of a autonomous, movable, robotic planter, which will be specifically designed for one plant: Sphagnum moss. In return for being given optimal conditions to thrive, the moss will purify the air of the indoor environment. Additionally, giving the plant the ability to move allows for optimal light and moisture tracking which keeps the moss healthy, while simultaneously purifying the air in multiple rooms of a home. Furthermore, using moss as the primary air filter allows this to be a zero waste system, unlike traditional HEPA filters. This project is significant because it is the first in-home autonomous system designed to keep moss healthy with no human input, while also representing a breakthrough in zero waste air cleaning capabilities. In the future, we would like to design this system for other types of human plant interactions, however for the purposes of this project air purification will be the focus.



## BAIJU Karthika

By exploring the unseen memories of everyday objects, my research “Hidden Stories of Everyday Objects” delves into the realm of more-than-human design (MTHD), ludic design, attachment to objects, and sustainability. This thesis aims to explore how the life stories of an object can illustrate its past usage, interactions with users, and its journey through time. The core theme of this work is using design as a tool to add memories to objects and using it to encourage better human-object relations. To do so, I conducted a design exploration by designing and fabricating a counterfactual artifact, a ceramic mug, following a “Thing Centered” perspective. The artifact embodies its journey through time and shares its life stories in the form of abstract images created from the different sounds that it hears in its life. This artifact is used to explore how a commonplace object within the household can be designed and created to share its memories as stories and how these stories can be used to foster human-object connection. This thesis is aimed at an unconventional look into the issue of disposable consumer culture, where objects are discarded and replaced quickly, leading to sustainability challenges. 
Humanity has reached a point where excessive consumption prevails simply because of the widespread availability of things. This has given rise to the throwaway culture, where objects are discarded before they reach their end of life. This research builds on the concept that a deeper understanding of the history of an object creates an emotional attachment which in turn results in prolonged life of the object.
The counterfactual artifact (ceramic mug) is specifically designed, guided by Ludic design principles, to capture, and express its memories and encourage human interaction with it. This mug doesn't just hold your drink; it listens to snippets of sound throughout its day—conversations, laughter, the morning silence, its movement across surfaces—and translates these moments into captivating abstract images. Each image is a captured moment in time, the language of the mug, and a way for humans to get a glimpse into the mug’s life. The display mechanism for these images is a crafted wooden block, which normally functions as a clock on a coffee table. However, when the mug is placed near this block, it displays the mug's memories – the abstract images generated from the sounds it hears. The exploration of the mug's stories is further encouraged by the use of conductive paint patterns on its surface. These patterns enable users to navigate through the mug's timeline, moving forward or backward in time. It emphasizes promoting sustainability by cultivating emotional attachments to objects in the house, thereby challenging the transient nature of modern consumer behavior and advocating for a more mindful and sustainable interaction with our material surroundings.
This work recognizes the inherent constraint of time and acknowledges the impracticality of conducting a field study with the designed artifact within the allotted time frame. The complexity of capturing meaningful responses from participants, particularly on a topic like attachment to objects, requires an extensive period of study, ideally spanning 3-4 months, to yield comprehensive outcomes. This could be expanded as a potential avenue of future work. Another envisioned area of future work is the creation of objects in a home setting with a narrative ecosystem, consisting of multiple household objects embodying memories and stories, and these stories intertwine with each object in the ecosystem. The central focus of this thesis revolves around the creation of an object that has narratives to tell about its life, interaction with humans being a part of its stories but not the whole.



# Middling


## KENT Helena

High science-value destinations in space, Earth and in the ocean are often extreme environments that are challenging to access. Scientists studying these locations can’t physically visit the sites they study, instead conducting research remotely, relying on scientific software to visualize and analyze their data. Exploration mission success is contingent on the use of such software for interpreting information, thus scientists’ experience while using these tools is an essential mission enabler. To improve the visualization and analysis of remotely collected data, this research extracts a set of human-centered AI (HCAI) principles and features for improving the design of scientific software from qualitative and quantitative analyses of prototype tests, interviews with scientists, and a survey of related research. HCAI is a field that focuses on “amplifying, augmenting, and enhancing human performance in ways that make systems reliable, safe, and trustworthy” [1, 2] in order to “support human self-efficacy, encourage creativity, clarify responsibility, and facilitate social participation” [1, 2] This research proposes that using the HCAI principles and features identified in our findings in the development of software for scientific applications will contribute to the improvement of remote exploration by supporting scientists’ engagement with information, thereby enabling the more effective exploration of new worlds.
	
The advancement of remote exploration technologies makes it increasingly feasible to return high fidelity data from distant environments, due to improvements in sensors, onboard computing, compression algorithms, and wireless data transmission technologies, amongst many other developments [3]. The increasing availability of data from remote destinations will need scientists’ analysis to successfully interpret it. Because of the increased volume of data, scientific software will be needed to determine what locations to explore, what types of data to collect, and how to analyze the data. Developing tools for scientists to analyze remote locations efficiently will enhance their interpretation and improve their understanding of these environments.

To address the increasing quantity of remote data, and the need for site-specific scientific research, the development of mission critical scientific software will be needed to enhance scientists' analysis, and to further their understanding of other, unexplored environments. The software used to collect and analyze data entirely mediates the experiences of scientists engaged in remote exploration. The design of that software directly affects the situational awareness of the scientists, the information they notice and interpret, and the actions that they take. The limitations of access to remote environments, in tandem with the data’s increasing quantity and complexity, presents challenges for the development of software that supports scientists in interacting with data from remote destinations.

This research contributes specifically by targeting scientists’ interactions with scientific software under scenarios where there may not be a second chance to collect data, resulting in high levels of pressure on scientists to make the right decisions about where to lead their investigations. Using HCAI methods to support software development is not a new endeavor [41]. However, there is no agreed upon method for HCAI to be integrated into the scientific software development process [42], and further, there is no agreed upon method for using HCAI methods specifically for the development of scientific software engaging with remote environments in space, Earth and the ocean. In this work, the novel approach of using existing HCAI methods in the development of scientific software for remote destinations may be one of many valuable approaches for enhancing scientists’ ability to more effectively engage with information from locations that have yet to be explored.



## GHOSH Samriddho

Pedestrian safety in Berkeley has been a concern for the last few years especially post-pandemic when the city has seen a surge in unsafe activities. While the city maintains relatively low violent crime and homicide rates compared to national averages, there have been increases in certain types of crimes and assaults. According to Berkeley Safe Transportation Research and Education Center, 21456 out of  24871 streets in Berkeley have reported some form of unsafe activity in the last 20 years. Continued emphasis on community engagement, targeted crime prevention strategies, and addressing underlying socioeconomic factors is crucial in further enhancing pedestrian safety in Berkeley. User research conducted in this exploration suggests pedestrians in Berkeley do not perceptively feel safe while they walk down the city of Berkeley owing to these unsafe events that occur. Based on surveys conducted by the author, these pedestrian subjects wish to navigate their way around the city feeling safe. Hence, the first part of the project explores data collection and processing where pedestrian subjects are invited to objectively rate various points within the city based on their perception of safety, armed with synthesis of WarnMe crime data and streetlight data of the city that would give a safety-rated map of Berkeley. A custom algorithm is designed to provide alternative routes optimizing distance and safety would provide the user with routes for safer navigation. With that being said, the fundamental limitation of this project lies in defining ‘perceived safety’ along with the quality of crowdsourced data and the inherent biases that accompany it. This work focuses on an implementational approach to pedestrian safety navigation that shall help users get a better understanding of the routes they take, enforcing collective responsibility and safer experiences. A large part of the future work would entail building robust data collection and processing systems, taking in the context of various social and spatial parameters to evaluate the perception of safety on a more holistic level.



## FEI Zeping
Technology advancement in artificial intelligence (AI) and machine learning (ML) has enabled rapid development in emotion AI. Products like MorphCast, Affectiva, and hume.ai are designed to gain insights into people’s facial expressions, which are applied to fields including automotive, media analysis, and marketing applications (“Affectiva,” n.d.; “MorphCase,” 2023; “Hume AI,” n.d.). According to Fortune Business Insights, the global affective computing market size is projected to reach $74.8 billion by 2029 (Emotion Detection and Recognition Market Size | Growth [2029], n.d.). This implies that human emotions will be massively collected by an increasing number of products in various industries in the near future. If this forecast were proved to be true, concerns and debates about emotional data privacy would undoubtedly reach a peak. When a niche technology such as emotion AI is scaled up and deeply integrated into our daily routines, individuals oftentimes cannot choose to opt out (consider mobile phones as an example), making the general public completely vulnerable in technological revolution. As AI continues to expand, it is crucial to take a pause and thoroughly examine the ethics of the technology itself and the approaches people are taking in product development so as to prevent catastrophe and design for a better future.

If We Had a Choice is a speculative design installation situated in a future where emotion recognition with AI technologies become ubiquitous. Change drivers and key events that lead us to this future are identified using frameworks introduced in Strategic Foresight, including backcasting, the Three Horizons, and STEEP (Lustig, 2015). Based on trend analysis and worldbuilding, four sets of video scenarios and artifacts and one participatory experience design are developed to demonstrate this speculated future. It critically extrapolates how emotion AI might shape everyday life in 2035, aiming to examine future trends of AI technology development, critique the power dynamics between vulnerable individuals and emerging technological trends, and spark discussion about the ethical and privacy concerns as well as what could go wrong in this future. It aspires to evoke researchers, designers, and technologists in creating responsible AI technologies for a preferable future.


## ANDRABI Syed Kabeer Ali

In the picturesque valleys of Kashmir, where indigenous handicrafts (e.g., Pashmina shawls, carpets, and papier-mâché) have thrived since the 15th century, pivotal cultural elements are at risk of fading into obscurity. Despite their historical significance, the influence of intermediaries has left artisans without due recognition and fair compensation, discouraging younger generations from preserving these traditional crafts. Additionally, three decades of political instability in Kashmir have isolated the region from the Western world, stalling the evolution of these designs and eroding the community's connection to these crafts. Despite interventions like state awards and global brand collaborations, the measures often face scalability issues and fall short of significantly improving artisans' livelihoods. Meanwhile, this occurs against a backdrop of growing demand for unique, custom-made design pieces in the contemporary world.
The core problem this thesis addresses is the growing disconnection between the rich, traditional crafts of the world in general and the modern designs. Despite the cultural significance and unique craftsmanship of these artisanal works, they remain undervalued and underexposed in contemporary design spaces. This disconnect not only threatens the survival of these heritage crafts but also overlooks their potential to enrich modern design. The thesis investigates how bridging this gap could not only preserve these traditions but also offer innovative design solutions for the modern consumer.
This thesis follows a structured double diamond design cycle, initiating with broad explorations that include stakeholder interviews, on-ground research in Kashmir, and comprehensive literature reviews to fully understand the context and challenges. Building on these insights, WeaveWorks was conceptualized and iteratively refined through continuous feedback, emerging as a pivotal digital platform that facilitates collaborative creation and enables the harmonious fusion of traditional Kashmiri craftsmanship with modern design applications.
A critical limitation of this study is the challenge of implementing the project technically, particularly in modifying not only the texture and pattern but also the geometry of artifacts, within the constrained timeline. Furthermore, the scope for identifying and engaging designers from various industries for collaboration with artisans is limited, owing to potential resource constraints. These factors delineate the boundaries of the current research, highlighting areas for further exploration and development in future iterations of WeaveWorks.
By leveraging these technologies, artisans will gain the opportunity to showcase their craftsmanship in the market and ultimately forge direct connections with designers spanning the globe. Such collaborations have the potential to birth a novel lineage of designs that seamlessly blend modern aesthetics with the rich tapestry of Kashmir's historical artistry. These designs, rooted in sustainability and echoing centuries of tradition, would not only cater to contemporary tastes but also narrate the timeless tales of Kashmir's artisanal legacy. The project's vision extends beyond Kashmir, aspiring to create a ripple effect that empowers artisans worldwide, fostering a global appreciation and revival of traditional craftsmanship in the modern design market.
The thesis can be viewed as an initial stride towards assisting artisans in rediscovering the fame and recognition they deserve. With the evolution of Generative AI, I plan to explore technologies like stable diffusion and ControlNet to deepen the collaborative process between artisans and designers and expand its reach globally to encompass a diverse range of crafts and design fields. These advancements promise to transform WeaveWorks into a more dynamic and inclusive platform, bridging traditional craftsmanship with modern design on a global scale. 


## DUARTE David

In the United States, a surprising observation is that young kids assign no more than six minutes a day to reading. This phenomenon begins at a crucial stage in youth when children are in a transition between picture books and alphabet books, being an abrupt change in children's reading habits. These findings are two among many pointed out by experts like Daniel Willingham, a professor at the University of Virginia, who has devoted substantial research into understanding the dynamics of reading habits (Willingham, 2015). This decline in reading, especially among the youth, is not isolated but mirrors global trends. According to Twenge & Campbell (2018), the seductive allure of screen time, coupled with an overwhelming influx of multimedia content, contributes significantly to this decline and is increasingly becoming more prevalent in our society
As adolescents mature, the deterioration in their reading habits becomes even more pronounced. Factors include diminishing motivation, echoed by McKenna et al. (2012), who found that reading attitudes notably change during the middle school years, is increasingly getting worse in the 21st century. External distractions, intensified by the omnipresence of mobile phones and other technologies (Kuznekoff & Titsworth, 2013), further exacerbate this issue. Moreover, there's a palpable lack of engagement with traditional reading methods. Baron (2015) notes that the digital age, with its quick, bite-sized information, challenges the conventional long-form reading styles.
To combat this, it's imperative to innovate and find newer methods that resonate with today's youth. Technologies like Augmented Reality (AR) and Virtual Reality (VR) have begun to show immense potential in education and reading habits (Johnson et al., 2011). These immersive technologies could provide a multisensory, gamified reading experience. By infusing reading with interactive elements similar to video games (Gee, 2003), educators and content creators have the potential to reignite the declining interest. Yet, it's crucial to approach this integration thoughtfully. As Gottfried & Schmitt (2014) point out, while multisensory experiences are enriching, there's a need for a balanced and well-curated union to ensure that one sensory input doesn't overshadow the reading experience.
The ultimate vision of this project is not just about replacing reading as a regular activity but also to transform it into an entertaining and immersive experience for the children that are in the transition from visual books to more complex readings. The paradigm is shifting from mere uni-sensory reading experiences to those that offer interactive, multisensory journeys (Dede, 2009). Such transitions, when handled smoothly, can renew a love for books and reading among the younger generation, challenging the traditional notions and expanding horizons. We are living in an era where the future of reading could be shaped in new ways, introducing new technologies such as AR/VR or even changing the paradigm of writing by shared authority with generative AI, re-understanding how stories are consumed and written.


# Weak

## HOSHIZAKI Ellie

Vibes are commonly defined as a person’s emotional state, or the atmosphere of a place, as communicated to and felt by others. Humans can sense special vibrations of atoms or groups of atoms, or the vibratory of song of the entire molecule [12]. However, a concise scientific explanation of how vibes are sensed is not readily available. Additionally, implicit context-driven sensing systems that understand people’s context of use are of paramount importance with the evolution of ubiquitous computing [4].
How can sensors detect data correlations in emotional affect perception and surroundings? How can we allow ourselves to be aware of the ambience in the room? How can we let ourselves feel the emotions of the person beside us through haptics, biosensors, and non-verbal communication? 
This thesis explores vibes, specifically how vibes can be measured using context-aware sensors and transmitted into new media outputs. Within the scope of this research, understanding the implications of emotional feelings on mental state and well-being roots the motivation. The significance is becoming more prevalent as societal pressures of the 21st century push toward receptiveness of emotional intelligence in workspaces. While navigating between in-person engagement, hybrid communication, and remote environments, this research focuses on visualizing one’s mood and its effect on other’s cognizance. How can we feel the vibe or portray feelings within a room in a non-verbal manner? This approach faces human struggles to portray emotional communication between the digital and physical world. Limits include displaying and/or quantifying something as ephemeral as vibes. 
The domain chosen for output is live music performances. An empathetic, amorphous blob reacts to human input. Data is collected and Machine Learning (ML) models look for patterns in order to measure vibes. A “vibe synthesizer” acts as an input processor powered by real time user interaction and biosensing data in concert with technological sensors measuring temperature and electric magnetic field.



## KADAM Ashwan

There is a statistically proven lack of positive South Asian representation in Western media today. While often resorting to stereotypical depictions of caricatures and threats, the very real impacts of these racially-insensitive displays on South Asian individuals have been anecdotally proven and statistically correlated. One particular result of such negative media depictions is the development of Internalized Racism, or the belief that negative stereotypes about one’s people are true. This belief leads to cyclic negative reinforcement that involves forming a negative self-image, or projecting those stereotypes onto others while simultaneously distancing their sense of self from their own racial identity.

The focus of this research is to develop a tool to combat the documented Internalized Racism in Indian-American communities. Specifically, it is proposed to create a new product of media that highlights the vast breadth of Indian culture and history, as well as Hindu mythology, in an authentic and respectful manner to promote sentiments of inclusion and community-building. The goal of this project is to encourage Indian children to be proud of their heritage, rather than feeling a sense of shame surrounding it, and to want to learn more about it.
For this project, it was decided through user feedback that an immersive Trading Card Game experience would be developed. Trading Card Games are excellent tools of community building, and immersive gaming technology has proven to get players invested in the world of the games they play. Marrying the two concepts, in conjunction with Indian culture, could create a game that allows players to become entrenched in the Indocentric universe they are playing in, thereby encouraging them to want to learn more about their culture. 
This game emphasizes real-world, tangible gameplay through various physical computing methods, while all digital game components are meant to act as assistive devices. This flips the narrative of current immersive gaming techniques, where tangible inputs drive digitally-rendered worlds. Additionally, this game utilizes Indofuturism as a narrative tool, to envision positive Indian characters within a future context.
The game that was developed consisted of a 22x22x7 inch gameboard that houses a host of electronics. There is a paired iOS app that helps players progress in the game by providing information about the game state, while also delivering information about the underlying foundations of the game. Additionally, 15 distinctive cards were developed using narrative techniques rooted in Indofuturism. The game was heavily influenced by user feedback, from form development, to game design, to information management. 
The game was ultimately successful in its playtesting with users in developing a sense of immersion and inclusion. Some feedback given was to provide users with more control over sensory experiences in the game, so they can modulate them.
Future work would include addressing the limitations of this current study. Particularly, finding a way to provide users with long-term exposure to the game can likely lead to more valuable insights on the game’s effectiveness in combating Internalized Racism.


## NIU Yilin

Tactile graphics is the current way for visually impaired students to learn about visual content. Strategically exploring tactile graphics is a skill that must be acquired. However, the traditional education method of using only hands as tools for touch learning is no longer suitable for blind people. As the Tangible and Accessibility Technology have found applications in different fields, its role in the blind education field has also been increasingly prominent. This has provided interaction designers with some inspirations. 

This study explores an innovative project to improve the effectiveness and autonomy of blind students in the educational field. In traditional settings, blind students usually require one-to-one education, but the efficiency and scalability of this model are challenged. Research has found that blind students are less efficient at transitioning between touch reference materials and graphics, and some blind students do not understand Braille and therefore require constant hands-on guidance.

In order to solve this problem, this research uses a variety of potential technologies, including gesture recognition, camera image recognition, Arduino hardware control, and wearable devices such as Apple Watch. Through the following two example scenarios, this project the author aims to implement a one-to-many education scenario model: In the first scenario, students are able to independently explore educational content. When the student's hand touches a specific location, the camera will identify the specific area, and the wearable will convey the content in the form of sound. In the second scenario, students can follow the teacher's guidance. Teachers can tap specific areas on their digital software to trigger the device to vibrate. At the same time, the camera can recognize the position of the student's hands, and the wearable product can provide voice guidance. Teachers can also track students’ progress in real time through software on their phones or computers.

Under the background of tangible and digital technology, the author believes that by using this product, the educational experience of blind students, their autonomy and efficiency can be improved, and it can also expand the accessibility of future educational resources. By integrating multiple technologies, this study aims to provide blind students with a more flexible and personalized educational experience, thereby opening up new possibilities for their educational paths.



## QIANCHENG Bao

In the dynamic landscape of Generative AI and Generative Arts, the quest for harnessing AI's creative potential remains ongoing. While Generative AI has offered a new realm of possibilities for creators, the current state of affairs falls short of delivering outcomes that are truly creative and unique. This discrepancy has prompted a growing need to augment the creative process by infusing personal style and innovation into AI-generated works.

Previous endeavors in the field have predominantly focused on utilizing Generative AI for 2D visual art, often with restricted input and output parameters. However, for creators seeking to push the boundaries of their craft, the potential lies in harnessing the power of 3D design generation coupled with inputs from non-visual art forms.

This project aspires to bridge this gap by developing a Generative AI tool capable of producing 3D designs based on audio inputs. These inputs may encompass a wide spectrum, ranging from music compositions and conversational dialogues to the intricate sounds of nature collected in a forest. By allowing creators to meld their distinctive tastes with the realm of non-visual arts, this tool aims to unlock artistic outcomes that transcend imagination.

One of the primary challenges faced during the project's development phase is the constraint of limited time and the inherent complexities of coding involved in creating such a sophisticated AI tool. Despite these challenges, the potential impact of this endeavor on the creative world cannot be overstated.

In the grander scheme of things, this project signifies a significant shift in the role of generative AI. It is evolving into a creative ally, amplifying the artistic journey rather than replacing it. With additional time and resources, the project holds the promise of refining the user interface, making it more accessible and user-friendly. Moreover, the quality of the 3D models generated can be further elevated to meet the demands of even the most discerning creators.
In conclusion, the quest to enhance creativity in Generative AI through 3D design generation from non-visual audio inputs is a bold step towards empowering creators with a transformative tool. As we navigate the uncharted waters of generative art, this project seeks to unlock the limitless potential of human-AI collaboration, enabling artists to breathe life into their unique visions like never before.

## ZHOU Ziyi

The field of occupational therapy plays a crucial role in supporting individuals with autism spectrum disorder (ASD) to enhance their cognitive, physical, and social functioning. ASD encompasses a range of developmental disorders that present challenges in social interaction, communication, and repetitive behaviors. Occupational therapists utilize various interventions to assist individuals with ASD in improving their daily living skills, independence, and overall quality of life.

One of the key elements in occupational therapy for individuals with ASD is the implementation of imitative practices. These practices hold significant importance as they serve as fundamental mechanisms for learning, communication, and social interaction. By promoting and facilitating imitative practices, occupational therapists can help foster the development of essential skills like play, language, and social reciprocity, which are often compromised in individuals with ASD.

The problem addressed in this study revolves around the limited availability and effectiveness of current imitative practices in occupational therapy for individuals with ASD. While the importance of imitation is recognized, several challenges and shortcomings exist in the implementation and outcomes of imitative interventions. Therefore, the research objectives of this study involve investigating the role and impact of imitative practices within occupational therapy, identifying areas for improvement, and developing an interactive and assistive product that enhances the efficacy of imitative interventions for individuals with ASD.





